---
layout: post
title: Workshop paper accepted to SIGIR 2025!
date: 2025-04-04 12:00:00
inline: false
related_posts: false
---

Written with colleagues at other universities, ["MMMORRF: Multimodal Multilingual Modularized Reciprocal Rank Fusion"](https://arxiv.org/abs/2503.20698), was accepted to SIGIR 2025 as a demo paper.

---

This paper was developed based on work done at the [Johns Hopkins University Human Language Technology Center of Excellence](https://hltcoe.jhu.edu/)'s [SCALE 2024 program](https://hltcoe.jhu.edu/research/scale/scale-2024/). We found that a pipeline approach composed of modality-specialized systems out-performed advanced multimodal models on some video retrieval tasks. Additionally, we found that fusing multiple modality-specific rankings derived from such components can be further improved by weighting rankings derived from visual features more heavily when text is expected to be scant based on the query.
